import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)#About Data"""AcknowledgementsAhmed H, Traore I, Saad S. “Detecting opinion spams and fake news using text classification”, Journal of Security and Privacy, Volume 1, Issue 1, Wiley, January/February 2018.Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138).InspirationCan you use this data set to make an algorithm able to determine if an article is fake news or not ?source: Kaggle"""#Read the Datadf_True = pd.read_csv('data/True.csv')df_Fake = pd.read_csv('data/Fake.csv')#Pippline"""ImportData EDATrain an LSTM ModelEvaluate trained model performance"""import tensorflow as tfimport matplotlib.pyplot as pltimport seaborn as snsfrom wordcloud import WordCloud, STOPWORDSimport nltkimport refrom nltk.stem import PorterStemmer, WordNetLemmatizerfrom nltk.corpus import stopwordsfrom nltk.tokenize import word_tokenize, sent_tokenizeimport gensimfrom gensim.utils import simple_preprocessfrom gensim.parsing.preprocessing import STOPWORDS#Now keras librariesfrom tensorflow.keras.preprocessing.text import one_hot, Tokenizerfrom tensorflow.keras.preprocessing.sequence import pad_sequencesfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectionalfrom tensorflow.keras.models import Modelfrom sklearn.metrics import accuracy_scorefrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_scoreimport seaborn as sns plt.style.use('ggplot')print(df_Fake.head(5))print(df_Fake.columns)print(df_True.head())print(df_True.columns)#check null valuesprint(df_Fake.isnull().sum())print(df_True.isnull().sum())#Check Data typeprint(df_Fake.subject.unique())print(df_True.subject.unique())#Get infoprint(df_Fake.info())print(df_True.info())# Data Exploratory Data Analysis (EDA) An Feature Engineering#an advice before cleaning or deletig something from df make copy of dataFake_df = df_Fake.copy()True_df = df_True.copy()#drop unuseles columns for usdf_Fake.drop(['date', 'subject'], axis=1, inplace=True)df_True.drop(['date', 'subject'], axis=1, inplace=True)#add a label/tag to datadf_Fake['class']=0df_True['class']=1#plot datasplt.figure(figsize=(10,5))plt.bar('Fake News', len(df_Fake), color='red')plt.bar('True News', len(df_True), color='green')plt.title('Distribution of Fake and True News', size=15)plt.xlabel('News Type', size=15)plt.ylabel('# of News Articles', size=15)print('Difference in news articles:',len(df_Fake)-len(df_True))#Time to concat both of datanews_df = pd.concat([df_Fake, df_True], ignore_index=True, sort=False)print(news_df)#make more useble datanews_df['text'] = news_df['title'] + news_df['text']news_df.drop('title', axis=1, inplace=True)#define target and featuresfeatures = news_df['text']targets = news_df['class']#Split data as X_train and X_testX_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.20, random_state=18)# NLP Engineering : cleaning textsdef normalize(data):    normalized = []    for i in data:        i = i.lower()        # get rid of urls        i = re.sub('https?://\S+|www\.\S+', '', i)        # get rid of non words and extra spaces        i = re.sub('\\W', ' ', i)        i = re.sub('\n', '', i)        i = re.sub(' +', ' ', i)        i = re.sub('^ ', '', i)        i = re.sub(' $', '', i)        normalized.append(i)    return normalizedX_train = normalize(X_train)X_test = normalize(X_test)#define Tokenizer numbersmax_vocab = 10000tokenizer = Tokenizer(num_words=max_vocab)#fit train data to Tokenizertokenizer.fit_on_texts(X_train)# tokenize the text into vectors X_train = tokenizer.texts_to_sequences(X_train)X_test = tokenizer.texts_to_sequences(X_test)#Build RNN (LSTM) modlemodel = tf.keras.Sequential([    tf.keras.layers.Embedding(max_vocab, 32),    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),    tf.keras.layers.Dense(64, activation='relu'),    tf.keras.layers.Dropout(0.5),    tf.keras.layers.Dense(1)])print(model.summary())#Preprocessind data for trainX_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=256)X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=256)# Train an LSTM Modelearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(1e-4),metrics=['accuracy'])history = model.fit(X_train, y_train, epochs=10,validation_split=0.1, batch_size=30, shuffle=True, callbacks=[early_stop])history_dict = history.history#get accuracyacc = history_dict['accuracy']val_acc = history_dict['val_accuracy']loss = history_dict['loss']val_loss = history_dict['val_loss']epochs = history.epoch#plot lossplt.figure(figsize=(12,9))plt.plot(epochs, loss, 'r', label='Training loss')plt.plot(epochs, val_loss, 'b', label='Validation loss')plt.title('Training and validation loss', size=20)plt.xlabel('Epochs', size=20)plt.ylabel('Loss', size=20)plt.legend(prop={'size': 20})plt.show()#plot accuracyplt.figure(figsize=(12,9))plt.plot(epochs, acc, 'g', label='Training acc')plt.plot(epochs, val_acc, 'b', label='Validation acc')plt.title('Training and validation accuracy', size=20)plt.xlabel('Epochs', size=20)plt.ylabel('Accuracy', size=20)plt.legend(prop={'size': 20})plt.ylim((0.5,1))plt.show()# Evulate trained model performance on Test datasetmodel.evaluate(X_test, y_test)#predict Test datasetpred = model.predict(X_test)binary_predictions = []for i in pred:    if i >= 0.5:        binary_predictions.append(1)    else:        binary_predictions.append(0)#print evulation resultsprint('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))print('Precision on testing set:', precision_score(binary_predictions, y_test))print('Recall on testing set:', recall_score(binary_predictions, y_test))#get and plot Confusion Matrix (it is important to understan for make a consult)matrix = confusion_matrix(binary_predictions, y_test, normalize='all')plt.figure(figsize=(16, 9))ax= plt.subplot()sns.heatmap(matrix, annot=True, ax = ax)# labels, title and ticksax.set_xlabel('Predicted Labels', size=20)ax.set_ylabel('True Labels', size=20)ax.set_title('Confusion Matrix', size=20) ax.xaxis.set_ticklabels([0,1], size=15)ax.yaxis.set_ticklabels([0,1], size=15)e = model.layers[0]weights = e.get_weights()[0]print(weights.shape) # shape: (vocab_size, embedding_dim)word_index = list(tokenizer.word_index.keys())word_index = word_index[:max_vocab-1]#output metadata and vectors data you can use for nest time to trainimport ioout_v = io.open('fakenews_vecs.tsv', 'w', encoding='utf-8')out_m = io.open('fakenews_meta.tsv', 'w', encoding='utf-8')for num, word in enumerate(word_index):  vec = weights[num+1] # skip 0, it's padding.  out_m.write(word + "\n")  out_v.write('\t'.join([str(x) for x in vec]) + "\n")out_v.close()out_m.close()